# Tesla M40 优化版 Dockerfile
# 针对 Tesla M40 (Compute Capability 5.2) 优化
# 使用 CUDA 11.8 确保兼容性

# 1. 使用 CUDA 11.8 兼容的基础镜像
FROM ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.0.0-gpu-cuda11.8-cudnn8.9-trt8.6

# 2. 设置工作目录并配置镜像源
WORKDIR /app
RUN sed -i 's|http://.*archive.ubuntu.com|https://mirrors.aliyun.com|g' /etc/apt/sources.list && \
    sed -i 's|http://.*security.ubuntu.com|https://mirrors.aliyun.com|g' /etc/apt/sources.list && \
    pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/

# 3. 安装必要的编译和运行依赖
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    git \
    cmake \
    ninja-build \
    gcc \
    g++ \
    make \
    wget \
    ca-certificates \
    python3-pip \
    python3-wheel && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    pip3 install --upgrade pip wheel

# 4. 安装 CUDA 11.8 工具链和NVIDIA驱动库
RUN wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb && \
    dpkg -i cuda-keyring_1.0-1_all.deb && \
    mkdir -p /etc/apt/sources.list.d && \
    touch /etc/apt/sources.list.d/cuda.list && \
    touch /etc/apt/sources.list.d/nvidia-ml.list && \
    sed -i 's|https://.*developer.download.nvidia.com|https://mirrors.aliyun.com/nvidia-cuda|g' /etc/apt/sources.list.d/cuda.list && \
    sed -i 's|https://.*developer.download.nvidia.com|https://mirrors.aliyun.com/nvidia-cuda|g' /etc/apt/sources.list.d/nvidia-ml.list && \
    apt-get update && \
    apt-get install -y \
        cuda-compiler-11-8 \
        cuda-libraries-dev-11-8 \
        cuda-driver-dev-11-8 \
        cuda-cudart-dev-11-8 \
        libcublas-dev-11-8 \
        libcurand-dev-11-8 \
        libcusparse-dev-11-8 \
        libcufft-dev-11-8 \
        libnvidia-compute-470 \
        nvidia-utils-470 && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    rm cuda-keyring_1.0-1_all.deb

# 5. 设置 CUDA 11.8 环境变量
ENV PATH=/usr/local/cuda-11.8/bin:${PATH}
ENV LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:${LD_LIBRARY_PATH}
ENV CUDA_HOME=/usr/local/cuda-11.8
ENV CUDAToolkit_ROOT=/usr/local/cuda-11.8

# 6. 验证基础镜像中的PaddlePaddle安装并配置 Maxwell 架构支持
RUN python3 -c "import paddle; print(f'PaddlePaddle版本: {paddle.__version__}'); print(f'GPU支持: {paddle.device.cuda.device_count() > 0}')" && \
    echo "PaddlePaddle验证完成" && \
    echo "配置 Maxwell 架构 (Compute Capability 5.2) 支持..." && \
    echo 'export CUDA_ARCH_LIST="5.2;6.0;6.1;7.0;7.5;8.0;8.6"' >> /etc/environment && \
    echo 'export PADDLE_WITH_CUDA=ON' >> /etc/environment && \
    echo 'export FLAGS_fraction_of_gpu_memory_to_use=0.8' >> /etc/environment

# 7. 安装项目依赖
COPY . /app/
RUN export SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True && \
    pip install pynvml -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com && \
    pip install --no-cache-dir -r work/requirement.txt && \
    chmod +x /app/entrypoint.sh

# 8. 设置 Tesla M40 特定的运行时环境
ENV CUDA_VISIBLE_DEVICES=0
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
# Maxwell 架构特定环境变量
ENV CUDA_ARCH_LIST="5.2;6.0;6.1;7.0;7.5;8.0;8.6"
ENV PADDLE_WITH_CUDA=ON
ENV FLAGS_fraction_of_gpu_memory_to_use=0.8
ENV FLAGS_conv_workspace_size_limit=512
ENV FLAGS_cudnn_exhaustive_search=1

# 9. 添加 Tesla M40 验证脚本
RUN echo '#!/bin/bash\n\
echo "=== Tesla M40 环境验证 ===\"\n\
echo "CUDA 版本:"\n\
nvcc --version\n\
echo "\nGPU 信息:"\n\
nvidia-smi\n\
echo "\nPaddlePaddle GPU 支持:"\n\
python -c "import paddle; print(f\"GPU 设备数量: {paddle.device.cuda.device_count()}\"); print(f\"GPU 设备名称: {paddle.device.cuda.get_device_name()}\")"\n\
echo "\n=== 验证完成 ===\"' > /app/verify_tesla_m40.sh && \
    chmod +x /app/verify_tesla_m40.sh

# 10. 启动命令
CMD ["/bin/bash"]

# Tesla M40 优化说明：
# - 使用 CUDA 11.8 确保与 Tesla M40 兼容
# - 添加 Compute Capability 5.2 特定编译参数
# - 使用浅克隆减少网络流量（节省约 2GB）
# - 精简 CUDA 组件安装（减少约 500MB 下载）
# - 编译后清理源码文件减少镜像大小
# - 添加环境验证脚本
